{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/synonym-pathfinder/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!python -m nltk.downloader wordnet"
      ],
      "metadata": {
        "id": "oUFqau33IGsA",
        "outputId": "05573501-78ab-46f4-b52c-a4041a90a082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "<frozen runpy>:128: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "JRfLf_Y6F2hS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WordNetGraph:\n",
        "    def __init__(self):\n",
        "        self.graph = nx.Graph()\n",
        "\n",
        "    def add_synset_node(self, synset):\n",
        "        self.graph.add_node(synset)"
      ],
      "metadata": {
        "id": "0xtVf5S6Ljwh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = WordNetGraph()\n",
        "\n",
        "synset1 = wn.synset('dog.n.01')\n",
        "synset2 = wn.synset('bank.n.01')\n",
        "graph.add_synset_node(synset1)\n",
        "graph.add_synset_node(synset2)\n",
        "\n",
        "print(f\"Nodes in graph: {list(graph.graph.nodes())}\")\n",
        "print(f\"Graph has {graph.graph.number_of_nodes()} nodes\")"
      ],
      "metadata": {
        "id": "PFiGzbLJL_QA",
        "outputId": "d915d0bb-131f-4d08-f475-66320486b016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes in graph: [Synset('dog.n.01'), Synset('bank.n.01')]\n",
            "Graph has 2 nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WordNetGraph:\n",
        "    def __init__(self):\n",
        "        self.graph = nx.Graph()\n",
        "\n",
        "    def add_synset_node(self, synset):\n",
        "        self.graph.add_node(synset)\n",
        "\n",
        "    def expand_from_word(self, word: str, max_degree: int):\n",
        "        \"\"\"\n",
        "        Create a graph of all synsets within max_degree from a starting word.\n",
        "\n",
        "        Args:\n",
        "            word: Starting word (e.g., 'bank')\n",
        "            max_degree: Maximum degree to expand (0 = just starting synsets)\n",
        "        \"\"\"\n",
        "        # Clear existing graph\n",
        "        self.graph.clear()\n",
        "\n",
        "        # Get all synsets for the starting word\n",
        "        starting_synsets = wn.synsets(word)\n",
        "        if not starting_synsets:\n",
        "            print(f\"No synsets found for '{word}'\")\n",
        "            return\n",
        "\n",
        "        print(f\"Starting with {len(starting_synsets)} synset(s) for '{word}':\")\n",
        "        for synset in starting_synsets:\n",
        "            print(f\"  - {synset.name()}: {synset.definition()[:50]}...\")\n",
        "            self.add_synset_node(synset)\n",
        "\n",
        "        # For degree 0, we're done\n",
        "        if max_degree == 0:\n",
        "            return\n",
        "\n",
        "        # Get hypernyms/hyponyms relationships for traversal\n",
        "        def neighbors(synset):\n",
        "            print('hyper:', synset.hypernyms(), 'hypo:', synset.hyponyms())\n",
        "            return list(synset.hypernyms()) + list(synset.hyponyms())\n",
        "\n",
        "        # Expand degree by degree\n",
        "        current_layer = set(starting_synsets)\n",
        "\n",
        "        for degree in range(1, max_degree + 1):\n",
        "            print(f\"\\nExpanding to degree {degree}...\")\n",
        "            next_layer = set()\n",
        "\n",
        "            for synset in current_layer:\n",
        "                new_neighbors = [n for n in neighbors(synset)\n",
        "                               if n not in self.graph]\n",
        "                for neighbor in new_neighbors:\n",
        "                    self.add_synset_node(neighbor)\n",
        "                    next_layer.add(neighbor)\n",
        "                    print(f\"  Added: {neighbor.name()}\")\n",
        "\n",
        "            current_layer = next_layer\n",
        "            if not current_layer:\n",
        "                print(f\"No more nodes at degree {degree}\")\n",
        "                break"
      ],
      "metadata": {
        "id": "tczolod8NeH2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create graph\n",
        "graph = WordNetGraph()\n",
        "\n",
        "# Expand from 'bank' up to degree 2\n",
        "#graph.expand_from_word('bank', max_degree=2)\n",
        "#print(f\"\\nFinal graph:\")\n",
        "#print(f\"Nodes in graph: {len(graph.graph.nodes())}\")\n",
        "#print(f\"Sample nodes: {list(graph.graph.nodes())[:5]}\")\n",
        "\n",
        "# Expand from 'home' up to degree 2\n",
        "graph.expand_from_word('tome', max_degree=2)\n",
        "print(f\"\\nFinal graph:\")\n",
        "print(f\"Nodes in graph: {len(graph.graph.nodes())}\")\n",
        "print(f\"Sample nodes: {list(graph.graph.nodes())[:5]}\")"
      ],
      "metadata": {
        "id": "EdH7oYYpNt5m",
        "outputId": "c8b09207-6f9a-48f3-f45e-a204e98eca33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting with 1 synset(s) for 'tome':\n",
            "  - tome.n.01: a (usually) large and scholarly book...\n",
            "\n",
            "Expanding to degree 1...\n",
            "hyper: [Synset('book.n.01')] hypo: []\n",
            "  Added: book.n.01\n",
            "\n",
            "Expanding to degree 2...\n",
            "hyper: [Synset('publication.n.01')] hypo: [Synset('prayer_book.n.01'), Synset('playbook.n.02'), Synset('curiosa.n.01'), Synset('pop-up_book.n.01'), Synset('bestiary.n.01'), Synset('reference_book.n.01'), Synset('booklet.n.01'), Synset('catechism.n.02'), Synset('trade_book.n.01'), Synset('yearbook.n.01'), Synset('formulary.n.01'), Synset('catalog.n.01'), Synset('review_copy.n.01'), Synset('workbook.n.01'), Synset('tome.n.01'), Synset('copybook.n.01'), Synset('songbook.n.01'), Synset('textbook.n.01'), Synset('authority.n.07'), Synset('phrase_book.n.01'), Synset('storybook.n.01'), Synset('appointment_book.n.01')]\n",
            "  Added: publication.n.01\n",
            "  Added: prayer_book.n.01\n",
            "  Added: playbook.n.02\n",
            "  Added: curiosa.n.01\n",
            "  Added: pop-up_book.n.01\n",
            "  Added: bestiary.n.01\n",
            "  Added: reference_book.n.01\n",
            "  Added: booklet.n.01\n",
            "  Added: catechism.n.02\n",
            "  Added: trade_book.n.01\n",
            "  Added: yearbook.n.01\n",
            "  Added: formulary.n.01\n",
            "  Added: catalog.n.01\n",
            "  Added: review_copy.n.01\n",
            "  Added: workbook.n.01\n",
            "  Added: copybook.n.01\n",
            "  Added: songbook.n.01\n",
            "  Added: textbook.n.01\n",
            "  Added: authority.n.07\n",
            "  Added: phrase_book.n.01\n",
            "  Added: storybook.n.01\n",
            "  Added: appointment_book.n.01\n",
            "\n",
            "Final graph:\n",
            "Nodes in graph: 24\n",
            "Sample nodes: [Synset('tome.n.01'), Synset('book.n.01'), Synset('publication.n.01'), Synset('prayer_book.n.01'), Synset('playbook.n.02')]\n"
          ]
        }
      ]
    }
  ]
}